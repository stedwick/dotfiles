# SPACESHIP_PROMPT_SEPARATE_LINE=false
SPACESHIP_NODE_SHOW=false
SPACESHIP_CHAR_SUFFIX=' '

bindkey '^[OA' history-beginning-search-backward
bindkey '^[OB' history-beginning-search-forward

# Turn off all beeps
unsetopt BEEP
# Turn off autocomplete beeps
# unsetopt LIST_BEEP
unsetopt share_history
unsetopt listambiguous
unalias rm

export EDITOR="vim"
export VISUAL="vim"
export LESS="-FRX"
export GPG_TTY="$(tty)" # for GPG
# export PATH="$PATH:$HOME/bin"
export DISABLE_AUTO_TITLE='true'

export RAILS_ENV="development"
export RACK_ENV="development"
export SYNCTA_DOCKER_IMG_BASE="quay.io/syncta/main-rails:FLOW326movefromsemaphoretokubernet"
# export AWS_DEFAULT_PROFILE="eb-cli"
# export AWS_PROFILE="eb-cli"

[ -r "$HOME/.syncta.secret.sh" ] && source "$HOME/.syncta.secret.sh"
[ -r "$HOME/bin/z.sh" ] && source "$HOME/bin/z.sh"

alias zz="clear"
alias c="cat"
alias e="vim"
alias a="ack -i"
alias aa="ack -i -A 5 -B 2"
# alias m="less -FX"
alias j="jobs"
alias ds="dirs -v"
alias cdiff="colordiff -u"
alias gs="git status"
alias gcs="git checkout staging"
alias gcp="git checkout philip"
alias gmm="git merge master"

alias d="docker"
alias dc="docker-compose"
function dct() {
  docker-compose -f ./config/devops/docker-compose.test.yml --project-directory . "$@"
}
function docker-tags () {
  name=$1
  # Initial URL
  url=https://registry.hub.docker.com/v2/repositories/$name/tags/?page_size=100
  (
    # Keep looping until the variable URL is empty
    while [ ! -z $url ]; do
      # Every iteration of the loop prints out a single dot to show progress as it got through all the pages (this is inline dot)
      >&2 echo -n "."
      # Curl the URL and pipe the output to Python. Python will parse the JSON and print the very first line as the next URL (it will leave it blank if there are no more pages)
      # then continue to loop over the results extracting only the name; all will be stored in a variable called content
      content=$(curl -s $url | python -c 'import sys, json; data = json.load(sys.stdin); print(data.get("next", "") or ""); print("\n".join([x["name"] for x in data["results"]]))')
      # Let's get the first line of content which contains the next URL for the loop to continue
      url=$(echo "$content" | head -n 1)
      # Print the content without the first line (yes +2 is counter intuitive)
      echo "$content" | tail -n +2
    done;
    # Finally break the line of dots
    >&2 echo
  ) | sort --version-sort | uniq;
}

# Fix completions
# rm ~/.zcompdump*
